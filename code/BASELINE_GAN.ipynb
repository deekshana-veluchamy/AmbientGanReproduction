{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IGNORE BASELINE GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1goe0ym82clt",
        "colab_type": "text"
      },
      "source": [
        "# Import Prequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty1SR-UkTrmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prerequisites\n",
        "from torch.autograd import Variable    \n",
        "import os, time\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import pickle\n",
        "import imageio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "#import torchbearer\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from skimage import color, data, restoration\n",
        "from scipy.signal import convolve2d\n",
        "from PIL import Image\n",
        "import glob\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import numpy as np\n",
        "import random \n",
        "import torch.utils.data as data\n",
        "from astropy.convolution import Gaussian2DKernel\n",
        "import cv2\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torchvision.utils import save_image\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q40rPmEYTiJ",
        "colab_type": "code",
        "outputId": "9533fa80-36b3-4a06-a9c2-213e35ad73be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmwb9Flof6D-",
        "colab_type": "text"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkSWLJFzuzOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        " \n",
        "'''\n",
        "    For the given path, get the List of all files in the directory tree \n",
        "'''\n",
        "def getListOfFiles(dirName):\n",
        "    # create a list of file and sub directories \n",
        "    # names in the given directory \n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    # Iterate over all the entries\n",
        "    for entry in listOfFile:\n",
        "        # Create full path\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        # If entry is a directory then get the list of files in this directory \n",
        "        if os.path.isdir(fullPath):\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)\n",
        "                \n",
        "    return allFiles  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL8VTautuwwg",
        "colab_type": "text"
      },
      "source": [
        "## Transformed images are saved before hand, and read from google drive folders to hasten learning process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iWf4JKpuEiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dirName = '/content/drive/My Drive/p_0.8/transformed_block_inverse_0.8'\n",
        "# Get the list of all files in directory tree at given path\n",
        "listOfFiles = getListOfFiles(dirName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bSkOmbvuG3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def atoi(text):\n",
        "    return int(text) if text.isdigit() else text\n",
        "\n",
        "def natural_keys(text):\n",
        "    '''\n",
        "    alist.sort(key=natural_keys) sorts in human order\n",
        "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
        "    (See Toothy's implementation in the comments)\n",
        "    '''\n",
        "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
        "\n",
        "\n",
        "listOfFiles.sort(key=natural_keys)\n",
        "#print(listOfFiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ_fe6fTuKgp",
        "colab_type": "code",
        "outputId": "c0459301-f530-4f03-f78f-1887a3413c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(listOfFiles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDFr1nrAvCD7",
        "colab_type": "text"
      },
      "source": [
        "## To ensure we''re reading the the right label for each image based on their index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ap8X8-muNET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexes = []\n",
        "def get_im_indexes(lis):\n",
        "  for element in lis:\n",
        "    \n",
        "    pref = '/content/drive/My Drive/p_0.8/transformed_block_inverse_0.8/transformed_block_p=0.8_index='\n",
        "    suff = '.pt'\n",
        "    x = element[len(pref):]\n",
        "    x = x[:-len(suff)]\n",
        "    indexes.append(int(x))\n",
        "  return indexes "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FepSlS6OxDy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_im_indexes(listOfFiles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtLcSnuuzFLA",
        "colab_type": "code",
        "outputId": "c3941402-57a8-44f0-ba4c-614a6d12d95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "data = np.load('/content/drive/My Drive/targets.npy',allow_pickle=True)\n",
        "#print(data.item())\n",
        "print(len(data.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhArWyH4zIa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_labels_array_form = list(data[()].values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_HoVeIzzKzg",
        "colab_type": "code",
        "outputId": "af359942-4bfc-436a-b8c5-bf9fff7e147a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        " \n",
        "Labels = torch.stack([torch.tensor(classlabel) for c,classlabel in enumerate(list_of_labels_array_form) if c in indexes])\n",
        "\n",
        "print(len(Labels))\n",
        "print(type(Labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38904\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v69ZmZOE3I-3",
        "colab_type": "text"
      },
      "source": [
        "# Construct Generator\n",
        "## Generator has 2 Convolutional layers, and 2 Linear layers as per specification by the authors of the Ambient GAN paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcjMin2eTxCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelG(nn.Module):\n",
        "    def __init__(self):\n",
        "        self.z_dim = 100\n",
        "        super(ModelG, self).__init__()\n",
        "        self.fc2 = nn.Linear(10, 1000)\n",
        "        self.fc = nn.Linear(self.z_dim+1000, 64*28*28)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.deconv1 = nn.ConvTranspose2d(64, 32, 5, 1, 2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.deconv2 = nn.ConvTranspose2d(32, 1, 5, 1, 2)\n",
        "    #weight_init\n",
        "    \n",
        "    def weight_init(self, mean, std):\n",
        "      for m in self._modules:\n",
        "        normal_init(self._modules[m], mean, std)\n",
        "        \n",
        "    def forward(self, x, labels):\n",
        "        batch_size = x.size(0)\n",
        "        y_ = self.fc2(labels)\n",
        "        y_ = F.relu(y_)\n",
        "        x = torch.cat([x, y_], 1)\n",
        "        x = self.fc(x)\n",
        "        x = x.view(batch_size, 64, 28, 28)\n",
        "        x = self.bn1(x) \n",
        "        x = F.relu(x)\n",
        "        x = self.deconv1(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = torch.tanh(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yXUAWZ83LUY",
        "colab_type": "text"
      },
      "source": [
        "# Construct Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX0V5VJ8UCdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelD, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, 1, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, 1, 2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.fc1  = nn.Linear(64*28*28+1000, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 1)\n",
        "        self.fc3 = nn.Linear(10, 1000)\n",
        "    # weight_init\n",
        "    \n",
        "    def weight_init(self, mean, std):\n",
        "      for m in self._modules:\n",
        "        normal_init(self._modules[m], mean, std)\n",
        "           \n",
        "    def forward(self, x, labels):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.view(batch_size, 1, 28,28)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(batch_size, 64*28*28)\n",
        "        y_ = self.fc3(labels)\n",
        "        y_ = F.relu(y_)\n",
        "        x = torch.cat([x, y_], 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO-yBKld3Os4",
        "colab_type": "text"
      },
      "source": [
        "# Provision to Initialize weights in D and G"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6Gsd24aWxMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uaFvzQK2-9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_SIZE = 784\n",
        "SAMPLE_SIZE = 1000\n",
        "NUM_LABELS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLXF1B2suifZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_d = ModelD()\n",
        "model_g = ModelG()\n",
        "criterion = nn.BCELoss()\n",
        "input = torch.FloatTensor(128, INPUT_SIZE)\n",
        "noise = torch.FloatTensor(128, (100))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aduBuilduUoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_noise = torch.FloatTensor(SAMPLE_SIZE, 100).normal_(0,1)\n",
        "fixed_labels = torch.zeros(SAMPLE_SIZE, NUM_LABELS)\n",
        "\n",
        "\n",
        "for i in range(NUM_LABELS):\n",
        "  for j in range(SAMPLE_SIZE // NUM_LABELS):\n",
        "    fixed_labels[i*(SAMPLE_SIZE // NUM_LABELS) + j, i] = 1.0\n",
        "    \n",
        "label = torch.FloatTensor(128)\n",
        "one_hot_labels = torch.FloatTensor(128, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEC8r-TvuX82",
        "colab_type": "code",
        "outputId": "12b8a860-0020-45a4-ddc1-403c371b2d28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "model_d.weight_init(mean=0.0, std=0.05)\n",
        "model_d.cuda()\n",
        "model_g.weight_init(mean=0.0, std=0.05)\n",
        "model_g.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelG(\n",
              "  (fc2): Linear(in_features=10, out_features=1000, bias=True)\n",
              "  (fc): Linear(in_features=1100, out_features=50176, bias=True)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (deconv1): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (deconv2): ConvTranspose2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R_IXbg5ulWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input, label = input.cuda(), label.cuda()\n",
        "noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
        "fixed_labels = fixed_labels.cuda()\n",
        "\n",
        "optim_d = optim.SGD(model_d.parameters(), lr=0.01)\n",
        "optim_g = optim.SGD(model_g.parameters(), lr=0.01)\n",
        "fixed_noise = Variable(fixed_noise.cuda())\n",
        "fixed_labels = Variable(fixed_labels.cuda())\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zrPH8xOztKO",
        "colab_type": "text"
      },
      "source": [
        "# Create custom dataset\n",
        "## create a dataset out of the images read from drive before feeding it to model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPxnam-NzwxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, file_paths, Labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.Labels = Labels\n",
        "        self.transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                             #transforms.Resize(img_size),\n",
        "                                              transforms.ToTensor(),\n",
        "                                             transforms.Normalize(mean=[0.5],std=[0.5])])\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = torch.load(self.file_paths[index])\n",
        "        y = self.Labels[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "            \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBYGdEzr1L_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "customdataset = MyDataset(listOfFiles, Labels)\n",
        "trainloader = DataLoader(\n",
        "    customdataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6V9EoEf1SZ2",
        "colab_type": "code",
        "outputId": "ba8359aa-757b-4d0e-bc4b-b5097c95312b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(customdataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKN9jxsMgKui",
        "colab_type": "text"
      },
      "source": [
        "# Train GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVmG4dgj2d-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_per_epoch_loss = []\n",
        "g_per_epoch_loss = []\n",
        "\n",
        "\n",
        "for epoch_idx in range(25):\n",
        "  \n",
        "  epoch_start_time = time.time()\n",
        "  \n",
        "  model_d.train()\n",
        "  model_g.train()\n",
        "  # learning rate decay\n",
        "  if (epoch_idx+1) == 15:\n",
        "        optim_d.param_groups[0]['lr'] /= 10\n",
        "        optim_g.param_groups[0]['lr'] /= 10\n",
        "        print(\"learning rate change!\")\n",
        "\n",
        "  if (epoch_idx+1) == 20:\n",
        "        optim_d.param_groups[0]['lr'] /= 10\n",
        "        optim_g.param_groups[0]['lr'] /= 10\n",
        "        print(\"learning rate change!\")\n",
        "\n",
        "  d_loss = []\n",
        "  g_loss = []\n",
        "  \n",
        "  for batch_idx, (train_x, train_y) in enumerate(trainloader):\n",
        "\n",
        "    batch_size = train_x.size(0)\n",
        "\n",
        "    train_x = train_x.view(-1, INPUT_SIZE)\n",
        "   \n",
        "    train_x = train_x.cuda()\n",
        "    train_y = train_y.cuda()\n",
        "\n",
        "    input.resize_as_(train_x).copy_(train_x)\n",
        "    label.resize_(batch_size).fill_(real_label)\n",
        "    one_hot_labels.resize_(batch_size, NUM_LABELS).zero_()\n",
        "    one_hot_labels = one_hot_labels.cuda()\n",
        "    one_hot_labels.scatter_(1, train_y.view(batch_size,1), 1)\n",
        "    inputv = Variable(input)\n",
        "    labelv = Variable(label)\n",
        "    \n",
        "    # ## Train D with all-real batch\n",
        "    output = model_d(inputv, Variable(one_hot_labels)) # Forward pass real batch through D\n",
        "    optim_d.zero_grad() # Calculate gradients for D in backward pass\n",
        "    errD_real = criterion(output, labelv) #nn.BCELoss() # Calculate loss on all-real batch\n",
        "    errD_real.backward()# Calculate gradients for D in backward pass\n",
        "    realD_mean = output.data.cpu().mean()\n",
        "    \n",
        "    # ## Train D with fake batch\n",
        "    one_hot_labels.zero_()\n",
        "    rand_y = torch.from_numpy(\n",
        "    np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
        "    one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
        "    noise.resize_(batch_size, 100).normal_(0,1)\n",
        "    label.resize_(batch_size).fill_(fake_label)\n",
        "    noisev = Variable(noise)\n",
        "    labelv = Variable(label)\n",
        "    onehotv = Variable(one_hot_labels)\n",
        "    g_out = model_g(noisev, onehotv)\n",
        "    output = model_d(g_out, onehotv)\n",
        "    errD_fake = criterion(output, labelv)\n",
        "    fakeD_mean = output.data.cpu().mean()\n",
        "    \n",
        "    # Add the gradients from the all-real and all-fake batches\n",
        "    errD = errD_real + errD_fake\n",
        "    errD_fake.backward()\n",
        "    optim_d.step() # optimize\n",
        "\n",
        "    # train the G\n",
        "    noise.normal_(0,1)\n",
        "    one_hot_labels.zero_()\n",
        "    rand_y = torch.from_numpy(\n",
        "    np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
        "    one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
        "    label.resize_(batch_size).fill_(real_label)\n",
        "    onehotv = Variable(one_hot_labels)\n",
        "    noisev = Variable(noise)\n",
        "    labelv = Variable(label)\n",
        "    g_out = model_g(noisev, onehotv)\n",
        "    output = model_d(g_out, onehotv)\n",
        "    errG = criterion(output, labelv)\n",
        "    optim_g.zero_grad()\n",
        "    errG.backward()\n",
        "    optim_g.step()\n",
        "  \n",
        "  \n",
        "    d_loss.append(errD)\n",
        "    g_loss.append(errG)\n",
        "    \n",
        "  epoch_end_time = time.time()  \n",
        "  \n",
        "  #g_out = model_g(fixed_noise, fixed_labels).data.view(SAMPLE_SIZE, 1, 28,28).cpu()\n",
        "  #save_image(g_out, '{}/{}.png'.format('/content/drive/My Drive/p_0.99/res_no_norm', epoch_idx))\n",
        " \n",
        "  \n",
        "  d_per_epoch_loss.append(torch.mean(torch.stack(d_loss),dim=0)) \n",
        "  g_per_epoch_loss.append(torch.mean(torch.stack(g_loss),dim=0))\n",
        "  \n",
        "  #data_to_is = for_is_calc(g_out)\n",
        "  #IS_DATA = DataLoader(data_to_is, shuffle=True, num_workers=4, pin_memory=torch.cuda.is_available())\n",
        "  \n",
        "  #if epoch_idx==24:\n",
        "  #  IScore.append(inception_score(data_to_is,cuda=True,resize=True,splits=10))\n",
        "  \n",
        "  \n",
        "  print('Epoch {} - D loss = {:.4f}, G loss = {:.4f}, Time taken in sec = {:.4f}'.format(epoch_idx, d_per_epoch_loss[epoch_idx], g_per_epoch_loss[epoch_idx],epoch_end_time-epoch_start_time))\n",
        "  #print(IScore)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fto-hJfwVv9",
        "colab_type": "text"
      },
      "source": [
        "# Calculate Inception Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuDqNFSKFRAE",
        "colab_type": "code",
        "outputId": "7ffb250b-fa2f-40e8-83d7-52d73f71775d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import os, sys\n",
        "try: \n",
        "    import torchbearer\n",
        "except:\n",
        "    !pip install torchbearer\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToTensor\n",
        "from skimage import color, data, restoration\n",
        "from scipy.signal import convolve2d\n",
        "from PIL import Image\n",
        "import glob\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from matplotlib.pyplot import imshow, imsave\n",
        "%matplotlib inline\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchbearer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/62/79c45d98e22e87b44c9b354d1b050526de80ac8a4da777126b7c86c2bb3e/torchbearer-0.3.0.tar.gz (84kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4 in /usr/local/lib/python3.6/dist-packages (from torchbearer) (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from torchbearer) (0.2.2.post3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchbearer) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4->torchbearer) (1.16.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->torchbearer) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->torchbearer) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->torchbearer) (0.46)\n",
            "Building wheels for collected packages: torchbearer\n",
            "  Building wheel for torchbearer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/cb/69/466aef9cee879fb8f645bd602e34d45e754fb3dee2cb1a877a\n",
            "Successfully built torchbearer\n",
            "Installing collected packages: torchbearer\n",
            "Successfully installed torchbearer-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6q_bEH-wbdd",
        "colab_type": "text"
      },
      "source": [
        "## We use the Better CNN model we created during labs, that gave >99% accuracy on prediction for MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WtmpccoFXy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "# Model Definition\n",
        "class BetterCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BetterCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 30, (5, 5), padding=0)\n",
        "        self.conv2 = nn.Conv2d(30, 15, (3, 3), padding=0)\n",
        "        self.fc1 = nn.Linear(15 * 5**2, 128)\n",
        "        self.fc2 = nn.Linear(128, 50)\n",
        "        self.fc3 = nn.Linear(50, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = F.relu(out)\n",
        "        out = F.max_pool2d(out, (2,2))\n",
        "        out = self.conv2(out)\n",
        "        out = F.relu(out)\n",
        "        out = F.max_pool2d(out, (2,2))\n",
        "        out = F.dropout(out,0.2)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        out = self.fc1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb8Im1nvFc-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.inception import inception_v3\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
        "    \"\"\"Computes the inception score of the generated images imgs\n",
        "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
        "    cuda -- whether or not to run on GPU\n",
        "    batch_size -- batch size for feeding into Inception v3\n",
        "    splits -- number of splits\n",
        "    \"\"\"\n",
        "    N = len(imgs)\n",
        "    print(N)\n",
        "    print(type(imgs))\n",
        "\n",
        "    assert batch_size > 0\n",
        "    assert N > batch_size\n",
        "\n",
        "    # Set up dtype\n",
        "    if cuda:\n",
        "        dtype = torch.cuda.FloatTensor\n",
        "    else:\n",
        "        if torch.cuda.is_available():\n",
        "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
        "        dtype = torch.FloatTensor\n",
        "\n",
        "    # Set up dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
        "\n",
        "    inception_model = BetterCNN()\n",
        "    inception_model.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/bettercnn.weights'))\n",
        "    inception_model.eval();\n",
        "\n",
        "   # up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n",
        "    def get_pred(x):\n",
        "        if resize:\n",
        "            x = up(x)\n",
        "        x = inception_model(x)\n",
        "        return F.softmax(x).data.cpu().numpy()\n",
        "\n",
        "    # Get predictions\n",
        "    preds = np.zeros((N, 10))\n",
        "\n",
        "    #for i, batch in enumerate(dataloader,0):\n",
        "        #batchv = Variable(batch[0])\n",
        "        #print(batchv.size())\n",
        "        #preds[i*batch_size:i*batch_size + batch_size] = get_pred(batchv)\n",
        "    print(imgs.size())\n",
        "    preds = get_pred(imgs)\n",
        "    # Now compute the mean kl-div\n",
        "    split_scores = []\n",
        "\n",
        "    for k in range(splits):\n",
        "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
        "        py = np.mean(part, axis=0)\n",
        "        scores = []\n",
        "        for i in range(part.shape[0]):\n",
        "            pyx = part[i, :]\n",
        "            scores.append(entropy(pyx, py))\n",
        "        split_scores.append(np.exp(np.mean(scores)))\n",
        "\n",
        "       \n",
        "    return np.mean(split_scores), np.std(split_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94j2LFikwoRM",
        "colab_type": "text"
      },
      "source": [
        "## Send 1000 images to Inception score module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UotIyZgZIE39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_out = model_g(fixed_noise, fixed_labels).data.view(1000, 1, 28,28).cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8dyg_kqIH3-",
        "colab_type": "code",
        "outputId": "e740bc68-38f3-4c81-8f9a-a195f6089e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(g_out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1mI5VtFUCUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyj6Iu7xwuaT",
        "colab_type": "text"
      },
      "source": [
        "## Record score for images of different amounts of measurement(p=0,0.1,0.5,0.8,0.9,0.95,0.99)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br1jpli05upW",
        "colab_type": "code",
        "outputId": "15dbb616-57d4-46a0-b298-d08ac9637068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "scores.append(inception_score(g_out, cuda=True, batch_size=32, resize=False, splits=1)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1000, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLRNHdreAVPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(scores) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INotbUIiUNFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseline_scores = [9.78,8.43,7.00, 6.84,3.63,2.87,1.73]\n",
        "ambient_gan_scores = [9.96,9.93,9.85,9.5,8.2,7.01,5.58] # collected from other gan\n",
        "vanilla_gan_scores = [9.94,6.93,3.13,1.50,1.21,1.19,1.05] # collected from other gan\n",
        "p_values = [0,0.1,0.5,0.8,0.9,0.95,0.99]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwVtMzorXwdX",
        "colab_type": "code",
        "outputId": "83b4511a-3daa-4643-9e2d-6f2305c29caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjUzlSY5Vw_k",
        "colab_type": "code",
        "outputId": "8eb9ad0b-544f-4981-8f16-e08720684749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "\n",
        "plt.plot(p_values,baseline_scores,c = 'g',label = 'Baseline')\n",
        "\n",
        "plt.plot(p_values,ambient_gan_scores,c = 'b',label = 'Ambient GAN')\n",
        "\n",
        "plt.plot(p_values,vanilla_gan_scores,c = 'r',label = 'Vanilla GAN')\n",
        "\n",
        "plt.xlabel('Block probability')\n",
        "plt.ylabel('Inception Score')\n",
        "plt.legend()\n",
        "plt.savefig('final.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBAeThKBEEJ4OEkEQgjh4SQRCCGEh/t/ruZy9tSe7pQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
